{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "        [transforms.Resize((256,256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "trainset_big = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "trainset = torch.utils.data.Subset(trainset_big,list(range(10000)))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "val_set = torch.utils.data.Subset(trainset_big,list(range(10000, 20000)))\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs):\n",
    "    best_model = model\n",
    "    best_loss = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        tr_correct = 0\n",
    "        tr_total = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        for batch_nr, (data, labels) in enumerate(train_loader):\n",
    "            \n",
    "            print(\"Epoch: \",epoch,\"Batch: \",batch_nr)\n",
    "            # calculate prediction according to our model\n",
    "            \n",
    "            prediction = model.forward(data)\n",
    "            # Calculate the loss of the prediction by comparing to the expected output\n",
    "            loss = criterion(prediction, labels)\n",
    "            \n",
    "            # Backpropagate the loss through the network to find the gradients of all parameters\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the parameters along their gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Clear stored gradient values\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # calculate accuracy\n",
    "            for i in range(len(data)):    \n",
    "                guess = torch.argmax(prediction[i])\n",
    "                if(guess.item() == labels[i]):\n",
    "                    tr_correct+=1\n",
    "                tr_total +=1\n",
    "\n",
    "\n",
    "\n",
    "        for batch_nr, (data, labels) in enumerate(val_loader):\n",
    "            \n",
    "            prediction = model.forward(data)\n",
    "            \n",
    "            # Calculate the loss of the prediction by comparing to the expected output\n",
    "            loss = criterion(prediction, labels)\n",
    "\n",
    "            if(loss < best_loss):\n",
    "                best_loss = loss\n",
    "                best_model = model\n",
    "\n",
    "            # calculate accuracy\n",
    "            for i in range(len(data)):    \n",
    "                guess = torch.argmax(prediction[i])\n",
    "                if(guess.item() == labels[i]):\n",
    "                    val_correct+=1\n",
    "                val_total +=1\n",
    "\n",
    "    # primt accuracy\n",
    "    tr_accuracy = tr_correct/tr_total\n",
    "    val_accuracy = val_correct/val_total\n",
    "    print(f'Training accuracy:   {str(100*tr_accuracy)[:4]}%.')\n",
    "    print(f'Validation accuracy: {str(100*val_accuracy)[:4]}%.')\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    for batch_nr, (data, labels) in enumerate(test_loader):\n",
    "        # print(\"ohno\")\n",
    "        prediction = model.forward(data)\n",
    "        \n",
    "        # calculate accuracy\n",
    "        for i in range(len(data)):    \n",
    "            guess = torch.argmax(prediction[i])\n",
    "            if(guess.item() == labels[i]):\n",
    "                val_correct+=1\n",
    "            val_total +=1\n",
    "\n",
    "    # primt accuracy\n",
    "    val_accuracy = val_correct/val_total\n",
    "    print(f'Test accuracy: {str(100*val_accuracy)[:4]}%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexNet_fineTuning = torchvision.models.alexnet(pretrained=True)\n",
    "alexNet_fineTuning.classifier[6] = nn.Linear(4096,10)\n",
    "\n",
    "# alexNet_fineTuning.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define for the optimization algorithm which parameters we want to update during training\n",
    "\n",
    "# Define our loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define our optimizer\n",
    "optimizer = torch.optim.Adam(alexNet_fineTuning.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Batch:  0\n",
      "Epoch:  0 Batch:  1\n",
      "Epoch:  0 Batch:  2\n",
      "Epoch:  0 Batch:  3\n",
      "Epoch:  0 Batch:  4\n",
      "Epoch:  0 Batch:  5\n",
      "Epoch:  0 Batch:  6\n",
      "Epoch:  0 Batch:  7\n",
      "Epoch:  0 Batch:  8\n",
      "Epoch:  0 Batch:  9\n",
      "Epoch:  0 Batch:  10\n",
      "Epoch:  0 Batch:  11\n",
      "Epoch:  0 Batch:  12\n",
      "Epoch:  0 Batch:  13\n",
      "Epoch:  0 Batch:  14\n",
      "Epoch:  0 Batch:  15\n",
      "Epoch:  0 Batch:  16\n",
      "Epoch:  0 Batch:  17\n",
      "Epoch:  0 Batch:  18\n",
      "Epoch:  0 Batch:  19\n",
      "Epoch:  1 Batch:  0\n",
      "Epoch:  1 Batch:  1\n",
      "Epoch:  1 Batch:  2\n",
      "Epoch:  1 Batch:  3\n",
      "Epoch:  1 Batch:  4\n",
      "Epoch:  1 Batch:  5\n",
      "Epoch:  1 Batch:  6\n",
      "Epoch:  1 Batch:  7\n",
      "Epoch:  1 Batch:  8\n",
      "Epoch:  1 Batch:  9\n",
      "Epoch:  1 Batch:  10\n",
      "Epoch:  1 Batch:  11\n",
      "Epoch:  1 Batch:  12\n",
      "Epoch:  1 Batch:  13\n",
      "Epoch:  1 Batch:  14\n",
      "Epoch:  1 Batch:  15\n",
      "Epoch:  1 Batch:  16\n",
      "Epoch:  1 Batch:  17\n",
      "Epoch:  1 Batch:  18\n",
      "Epoch:  1 Batch:  19\n",
      "Epoch:  2 Batch:  0\n",
      "Epoch:  2 Batch:  1\n",
      "Epoch:  2 Batch:  2\n",
      "Epoch:  2 Batch:  3\n",
      "Epoch:  2 Batch:  4\n",
      "Epoch:  2 Batch:  5\n",
      "Epoch:  2 Batch:  6\n",
      "Epoch:  2 Batch:  7\n",
      "Epoch:  2 Batch:  8\n",
      "Epoch:  2 Batch:  9\n",
      "Epoch:  2 Batch:  10\n",
      "Epoch:  2 Batch:  11\n",
      "Epoch:  2 Batch:  12\n",
      "Epoch:  2 Batch:  13\n",
      "Epoch:  2 Batch:  14\n",
      "Epoch:  2 Batch:  15\n",
      "Epoch:  2 Batch:  16\n",
      "Epoch:  2 Batch:  17\n",
      "Epoch:  2 Batch:  18\n",
      "Epoch:  2 Batch:  19\n",
      "Epoch:  3 Batch:  0\n",
      "Epoch:  3 Batch:  1\n",
      "Epoch:  3 Batch:  2\n",
      "Epoch:  3 Batch:  3\n",
      "Epoch:  3 Batch:  4\n",
      "Epoch:  3 Batch:  5\n",
      "Epoch:  3 Batch:  6\n",
      "Epoch:  3 Batch:  7\n",
      "Epoch:  3 Batch:  8\n",
      "Epoch:  3 Batch:  9\n",
      "Epoch:  3 Batch:  10\n",
      "Epoch:  3 Batch:  11\n",
      "Epoch:  3 Batch:  12\n",
      "Epoch:  3 Batch:  13\n",
      "Epoch:  3 Batch:  14\n",
      "Epoch:  3 Batch:  15\n",
      "Epoch:  3 Batch:  16\n",
      "Epoch:  3 Batch:  17\n",
      "Epoch:  3 Batch:  18\n",
      "Epoch:  3 Batch:  19\n",
      "Epoch:  4 Batch:  0\n",
      "Epoch:  4 Batch:  1\n",
      "Epoch:  4 Batch:  2\n",
      "Epoch:  4 Batch:  3\n",
      "Epoch:  4 Batch:  4\n",
      "Epoch:  4 Batch:  5\n",
      "Epoch:  4 Batch:  6\n",
      "Epoch:  4 Batch:  7\n",
      "Epoch:  4 Batch:  8\n",
      "Epoch:  4 Batch:  9\n",
      "Epoch:  4 Batch:  10\n",
      "Epoch:  4 Batch:  11\n",
      "Epoch:  4 Batch:  12\n",
      "Epoch:  4 Batch:  13\n",
      "Epoch:  4 Batch:  14\n",
      "Epoch:  4 Batch:  15\n",
      "Epoch:  4 Batch:  16\n",
      "Epoch:  4 Batch:  17\n",
      "Epoch:  4 Batch:  18\n",
      "Epoch:  4 Batch:  19\n",
      "Epoch:  5 Batch:  0\n",
      "Epoch:  5 Batch:  1\n",
      "Epoch:  5 Batch:  2\n",
      "Epoch:  5 Batch:  3\n",
      "Epoch:  5 Batch:  4\n",
      "Epoch:  5 Batch:  5\n",
      "Epoch:  5 Batch:  6\n",
      "Epoch:  5 Batch:  7\n",
      "Epoch:  5 Batch:  8\n",
      "Epoch:  5 Batch:  9\n",
      "Epoch:  5 Batch:  10\n",
      "Epoch:  5 Batch:  11\n",
      "Epoch:  5 Batch:  12\n",
      "Epoch:  5 Batch:  13\n",
      "Epoch:  5 Batch:  14\n",
      "Epoch:  5 Batch:  15\n",
      "Epoch:  5 Batch:  16\n",
      "Epoch:  5 Batch:  17\n",
      "Epoch:  5 Batch:  18\n",
      "Epoch:  5 Batch:  19\n",
      "Epoch:  6 Batch:  0\n",
      "Epoch:  6 Batch:  1\n",
      "Epoch:  6 Batch:  2\n",
      "Epoch:  6 Batch:  3\n",
      "Epoch:  6 Batch:  4\n",
      "Epoch:  6 Batch:  5\n",
      "Epoch:  6 Batch:  6\n",
      "Epoch:  6 Batch:  7\n",
      "Epoch:  6 Batch:  8\n",
      "Epoch:  6 Batch:  9\n",
      "Epoch:  6 Batch:  10\n",
      "Epoch:  6 Batch:  11\n",
      "Epoch:  6 Batch:  12\n",
      "Epoch:  6 Batch:  13\n",
      "Epoch:  6 Batch:  14\n",
      "Epoch:  6 Batch:  15\n",
      "Epoch:  6 Batch:  16\n",
      "Epoch:  6 Batch:  17\n",
      "Epoch:  6 Batch:  18\n",
      "Epoch:  6 Batch:  19\n",
      "Epoch:  7 Batch:  0\n",
      "Epoch:  7 Batch:  1\n",
      "Epoch:  7 Batch:  2\n",
      "Epoch:  7 Batch:  3\n",
      "Epoch:  7 Batch:  4\n",
      "Epoch:  7 Batch:  5\n",
      "Epoch:  7 Batch:  6\n",
      "Epoch:  7 Batch:  7\n",
      "Epoch:  7 Batch:  8\n",
      "Epoch:  7 Batch:  9\n",
      "Epoch:  7 Batch:  10\n",
      "Epoch:  7 Batch:  11\n",
      "Epoch:  7 Batch:  12\n",
      "Epoch:  7 Batch:  13\n",
      "Epoch:  7 Batch:  14\n",
      "Epoch:  7 Batch:  15\n",
      "Epoch:  7 Batch:  16\n",
      "Epoch:  7 Batch:  17\n",
      "Epoch:  7 Batch:  18\n",
      "Epoch:  7 Batch:  19\n",
      "Epoch:  8 Batch:  0\n",
      "Epoch:  8 Batch:  1\n",
      "Epoch:  8 Batch:  2\n",
      "Epoch:  8 Batch:  3\n",
      "Epoch:  8 Batch:  4\n",
      "Epoch:  8 Batch:  5\n",
      "Epoch:  8 Batch:  6\n",
      "Epoch:  8 Batch:  7\n",
      "Epoch:  8 Batch:  8\n",
      "Epoch:  8 Batch:  9\n",
      "Epoch:  8 Batch:  10\n",
      "Epoch:  8 Batch:  11\n",
      "Epoch:  8 Batch:  12\n",
      "Epoch:  8 Batch:  13\n",
      "Epoch:  8 Batch:  14\n",
      "Epoch:  8 Batch:  15\n",
      "Epoch:  8 Batch:  16\n",
      "Epoch:  8 Batch:  17\n",
      "Epoch:  8 Batch:  18\n",
      "Epoch:  8 Batch:  19\n",
      "Epoch:  9 Batch:  0\n",
      "Epoch:  9 Batch:  1\n",
      "Epoch:  9 Batch:  2\n",
      "Epoch:  9 Batch:  3\n",
      "Epoch:  9 Batch:  4\n",
      "Epoch:  9 Batch:  5\n",
      "Epoch:  9 Batch:  6\n",
      "Epoch:  9 Batch:  7\n",
      "Epoch:  9 Batch:  8\n",
      "Epoch:  9 Batch:  9\n",
      "Epoch:  9 Batch:  10\n",
      "Epoch:  9 Batch:  11\n",
      "Epoch:  9 Batch:  12\n",
      "Epoch:  9 Batch:  13\n",
      "Epoch:  9 Batch:  14\n",
      "Epoch:  9 Batch:  15\n",
      "Epoch:  9 Batch:  16\n",
      "Epoch:  9 Batch:  17\n",
      "Epoch:  9 Batch:  18\n",
      "Epoch:  9 Batch:  19\n",
      "Training accuracy:   33.5%.\n",
      "Validation accuracy: 34.4%.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the training step\n",
    "train_model(alexNet_fineTuning,criterion,optimizer,trainloader,val_loader,num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier.6.weight tensor([[ 0.0061, -0.0003, -0.0059,  ...,  0.0097,  0.0109,  0.0074],\n",
      "        [ 0.0108,  0.0139, -0.0114,  ..., -0.0045, -0.0047,  0.0107],\n",
      "        [-0.0038,  0.0126, -0.0131,  ...,  0.0013, -0.0023, -0.0046],\n",
      "        ...,\n",
      "        [-0.0079, -0.0107,  0.0092,  ..., -0.0069, -0.0136, -0.0094],\n",
      "        [ 0.0065,  0.0043, -0.0061,  ..., -0.0052,  0.0021, -0.0071],\n",
      "        [ 0.0156, -0.0142, -0.0107,  ..., -0.0050,  0.0037, -0.0087]])\n",
      "classifier.6.bias tensor([-0.0078, -0.0155, -0.0026, -0.0136, -0.0021,  0.0057,  0.0017, -0.0139,\n",
      "        -0.0072,  0.0117])\n"
     ]
    }
   ],
   "source": [
    "# Define for the optimization algorithm which parameters we want to update during training\n",
    "alexNet_featureExtraction = torchvision.models.alexnet(pretrained=True)\n",
    "\n",
    "for param in alexNet_featureExtraction.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "alexNet_featureExtraction.classifier[6] = nn.Linear(4096,10)\n",
    "# find the paramaters we want to update during training\n",
    "params_to_update = []\n",
    "for param in alexNet_featureExtraction.parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "\n",
    "for name, param in alexNet_featureExtraction.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data)\n",
    "\n",
    "# Define our loss function\n",
    "criterion_fe = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define our optimizer\n",
    "optimizer_fe = torch.optim.Adam(params_to_update, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Batch:  0\n",
      "Epoch:  0 Batch:  1\n",
      "Epoch:  0 Batch:  2\n",
      "Epoch:  0 Batch:  3\n",
      "Epoch:  0 Batch:  4\n",
      "Epoch:  0 Batch:  5\n",
      "Epoch:  0 Batch:  6\n",
      "Epoch:  0 Batch:  7\n",
      "Epoch:  0 Batch:  8\n",
      "Epoch:  0 Batch:  9\n",
      "Epoch:  0 Batch:  10\n",
      "Epoch:  0 Batch:  11\n",
      "Epoch:  0 Batch:  12\n",
      "Epoch:  0 Batch:  13\n",
      "Epoch:  0 Batch:  14\n",
      "Epoch:  0 Batch:  15\n",
      "Epoch:  0 Batch:  16\n",
      "Epoch:  0 Batch:  17\n",
      "Epoch:  0 Batch:  18\n",
      "Epoch:  0 Batch:  19\n",
      "Epoch:  1 Batch:  0\n",
      "Epoch:  1 Batch:  1\n",
      "Epoch:  1 Batch:  2\n",
      "Epoch:  1 Batch:  3\n",
      "Epoch:  1 Batch:  4\n",
      "Epoch:  1 Batch:  5\n",
      "Epoch:  1 Batch:  6\n",
      "Epoch:  1 Batch:  7\n",
      "Epoch:  1 Batch:  8\n",
      "Epoch:  1 Batch:  9\n",
      "Epoch:  1 Batch:  10\n",
      "Epoch:  1 Batch:  11\n",
      "Epoch:  1 Batch:  12\n",
      "Epoch:  1 Batch:  13\n",
      "Epoch:  1 Batch:  14\n",
      "Epoch:  1 Batch:  15\n",
      "Epoch:  1 Batch:  16\n",
      "Epoch:  1 Batch:  17\n",
      "Epoch:  1 Batch:  18\n",
      "Epoch:  1 Batch:  19\n",
      "Epoch:  2 Batch:  0\n",
      "Epoch:  2 Batch:  1\n",
      "Epoch:  2 Batch:  2\n",
      "Epoch:  2 Batch:  3\n",
      "Epoch:  2 Batch:  4\n",
      "Epoch:  2 Batch:  5\n",
      "Epoch:  2 Batch:  6\n",
      "Epoch:  2 Batch:  7\n",
      "Epoch:  2 Batch:  8\n",
      "Epoch:  2 Batch:  9\n",
      "Epoch:  2 Batch:  10\n",
      "Epoch:  2 Batch:  11\n",
      "Epoch:  2 Batch:  12\n",
      "Epoch:  2 Batch:  13\n",
      "Epoch:  2 Batch:  14\n",
      "Epoch:  2 Batch:  15\n",
      "Epoch:  2 Batch:  16\n",
      "Epoch:  2 Batch:  17\n",
      "Epoch:  2 Batch:  18\n",
      "Epoch:  2 Batch:  19\n",
      "Epoch:  3 Batch:  0\n",
      "Epoch:  3 Batch:  1\n",
      "Epoch:  3 Batch:  2\n",
      "Epoch:  3 Batch:  3\n",
      "Epoch:  3 Batch:  4\n",
      "Epoch:  3 Batch:  5\n",
      "Epoch:  3 Batch:  6\n",
      "Epoch:  3 Batch:  7\n",
      "Epoch:  3 Batch:  8\n",
      "Epoch:  3 Batch:  9\n",
      "Epoch:  3 Batch:  10\n",
      "Epoch:  3 Batch:  11\n",
      "Epoch:  3 Batch:  12\n",
      "Epoch:  3 Batch:  13\n",
      "Epoch:  3 Batch:  14\n",
      "Epoch:  3 Batch:  15\n",
      "Epoch:  3 Batch:  16\n",
      "Epoch:  3 Batch:  17\n",
      "Epoch:  3 Batch:  18\n",
      "Epoch:  3 Batch:  19\n",
      "Epoch:  4 Batch:  0\n",
      "Epoch:  4 Batch:  1\n",
      "Epoch:  4 Batch:  2\n",
      "Epoch:  4 Batch:  3\n",
      "Epoch:  4 Batch:  4\n",
      "Epoch:  4 Batch:  5\n",
      "Epoch:  4 Batch:  6\n",
      "Epoch:  4 Batch:  7\n",
      "Epoch:  4 Batch:  8\n",
      "Epoch:  4 Batch:  9\n",
      "Epoch:  4 Batch:  10\n",
      "Epoch:  4 Batch:  11\n",
      "Epoch:  4 Batch:  12\n",
      "Epoch:  4 Batch:  13\n",
      "Epoch:  4 Batch:  14\n",
      "Epoch:  4 Batch:  15\n",
      "Epoch:  4 Batch:  16\n",
      "Epoch:  4 Batch:  17\n",
      "Epoch:  4 Batch:  18\n",
      "Epoch:  4 Batch:  19\n",
      "Epoch:  5 Batch:  0\n",
      "Epoch:  5 Batch:  1\n",
      "Epoch:  5 Batch:  2\n",
      "Epoch:  5 Batch:  3\n",
      "Epoch:  5 Batch:  4\n",
      "Epoch:  5 Batch:  5\n",
      "Epoch:  5 Batch:  6\n",
      "Epoch:  5 Batch:  7\n",
      "Epoch:  5 Batch:  8\n",
      "Epoch:  5 Batch:  9\n",
      "Epoch:  5 Batch:  10\n",
      "Epoch:  5 Batch:  11\n",
      "Epoch:  5 Batch:  12\n",
      "Epoch:  5 Batch:  13\n",
      "Epoch:  5 Batch:  14\n",
      "Epoch:  5 Batch:  15\n",
      "Epoch:  5 Batch:  16\n",
      "Epoch:  5 Batch:  17\n",
      "Epoch:  5 Batch:  18\n",
      "Epoch:  5 Batch:  19\n",
      "Epoch:  6 Batch:  0\n",
      "Epoch:  6 Batch:  1\n",
      "Epoch:  6 Batch:  2\n",
      "Epoch:  6 Batch:  3\n",
      "Epoch:  6 Batch:  4\n",
      "Epoch:  6 Batch:  5\n",
      "Epoch:  6 Batch:  6\n",
      "Epoch:  6 Batch:  7\n",
      "Epoch:  6 Batch:  8\n",
      "Epoch:  6 Batch:  9\n",
      "Epoch:  6 Batch:  10\n",
      "Epoch:  6 Batch:  11\n",
      "Epoch:  6 Batch:  12\n",
      "Epoch:  6 Batch:  13\n",
      "Epoch:  6 Batch:  14\n",
      "Epoch:  6 Batch:  15\n",
      "Epoch:  6 Batch:  16\n",
      "Epoch:  6 Batch:  17\n",
      "Epoch:  6 Batch:  18\n",
      "Epoch:  6 Batch:  19\n",
      "Epoch:  7 Batch:  0\n",
      "Epoch:  7 Batch:  1\n",
      "Epoch:  7 Batch:  2\n",
      "Epoch:  7 Batch:  3\n",
      "Epoch:  7 Batch:  4\n",
      "Epoch:  7 Batch:  5\n",
      "Epoch:  7 Batch:  6\n",
      "Epoch:  7 Batch:  7\n",
      "Epoch:  7 Batch:  8\n",
      "Epoch:  7 Batch:  9\n",
      "Epoch:  7 Batch:  10\n",
      "Epoch:  7 Batch:  11\n",
      "Epoch:  7 Batch:  12\n",
      "Epoch:  7 Batch:  13\n",
      "Epoch:  7 Batch:  14\n",
      "Epoch:  7 Batch:  15\n",
      "Epoch:  7 Batch:  16\n",
      "Epoch:  7 Batch:  17\n",
      "Epoch:  7 Batch:  18\n",
      "Epoch:  7 Batch:  19\n",
      "Epoch:  8 Batch:  0\n",
      "Epoch:  8 Batch:  1\n",
      "Epoch:  8 Batch:  2\n",
      "Epoch:  8 Batch:  3\n",
      "Epoch:  8 Batch:  4\n",
      "Epoch:  8 Batch:  5\n",
      "Epoch:  8 Batch:  6\n",
      "Epoch:  8 Batch:  7\n",
      "Epoch:  8 Batch:  8\n",
      "Epoch:  8 Batch:  9\n",
      "Epoch:  8 Batch:  10\n",
      "Epoch:  8 Batch:  11\n",
      "Epoch:  8 Batch:  12\n",
      "Epoch:  8 Batch:  13\n",
      "Epoch:  8 Batch:  14\n",
      "Epoch:  8 Batch:  15\n",
      "Epoch:  8 Batch:  16\n",
      "Epoch:  8 Batch:  17\n",
      "Epoch:  8 Batch:  18\n",
      "Epoch:  8 Batch:  19\n",
      "Epoch:  9 Batch:  0\n",
      "Epoch:  9 Batch:  1\n",
      "Epoch:  9 Batch:  2\n",
      "Epoch:  9 Batch:  3\n",
      "Epoch:  9 Batch:  4\n",
      "Epoch:  9 Batch:  5\n",
      "Epoch:  9 Batch:  6\n",
      "Epoch:  9 Batch:  7\n",
      "Epoch:  9 Batch:  8\n",
      "Epoch:  9 Batch:  9\n",
      "Epoch:  9 Batch:  10\n",
      "Epoch:  9 Batch:  11\n",
      "Epoch:  9 Batch:  12\n",
      "Epoch:  9 Batch:  13\n",
      "Epoch:  9 Batch:  14\n",
      "Epoch:  9 Batch:  15\n",
      "Epoch:  9 Batch:  16\n",
      "Epoch:  9 Batch:  17\n",
      "Epoch:  9 Batch:  18\n",
      "Epoch:  9 Batch:  19\n",
      "Training accuracy:   76.0%.\n",
      "Validation accuracy: 70.9%.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the training step\n",
    "train_model(alexNet_featureExtraction,criterion_fe,optimizer_fe,trainloader,val_loader,num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine Tuning:\n",
      "Test accuracy: 35.5%.\n",
      "\n",
      "Feature Extraction:\n",
      "Test accuracy: 71.5%.\n"
     ]
    }
   ],
   "source": [
    "print(\"Fine Tuning:\")\n",
    "test_model(alexNet_fineTuning, testloader)\n",
    "\n",
    "print(\"\\nFeature Extraction:\")\n",
    "test_model(alexNet_featureExtraction, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "trainset_MNIST_big = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "trainset_MNIST = torch.utils.data.Subset(trainset_MNIST_big,list(range(10000)))\n",
    "\n",
    "trainloader_MNIST = torch.utils.data.DataLoader(trainset_MNIST, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "val_set_MNIST = torch.utils.data.Subset(trainset_MNIST_big,list(range(10000, 20000)))\n",
    "val_loader_MNIST = torch.utils.data.DataLoader(val_set_MNIST, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "                                          \n",
    "testset_MNIST = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader_MNIST = torch.utils.data.DataLoader(testset_MNIST, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chose ResNet-18 as CNN model\n",
    "resnet = torchvision.models.resnet18(pretrained= False)\n",
    "resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "# optimizer = torch.optim.Adam(params_to_update, lr=0.001)\n",
    "optimizer = torch.optim.Adam(resnet.parameters(), lr=0.001)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Batch:  0\n",
      "Epoch:  0 Batch:  1\n",
      "Epoch:  0 Batch:  2\n",
      "Epoch:  0 Batch:  3\n",
      "Epoch:  0 Batch:  4\n",
      "Epoch:  0 Batch:  5\n",
      "Epoch:  0 Batch:  6\n",
      "Epoch:  0 Batch:  7\n",
      "Epoch:  0 Batch:  8\n",
      "Epoch:  0 Batch:  9\n",
      "Epoch:  0 Batch:  10\n",
      "Epoch:  0 Batch:  11\n",
      "Epoch:  0 Batch:  12\n",
      "Epoch:  0 Batch:  13\n",
      "Epoch:  0 Batch:  14\n",
      "Epoch:  0 Batch:  15\n",
      "Epoch:  0 Batch:  16\n",
      "Epoch:  0 Batch:  17\n",
      "Epoch:  0 Batch:  18\n",
      "Epoch:  0 Batch:  19\n",
      "Epoch:  1 Batch:  0\n",
      "Epoch:  1 Batch:  1\n",
      "Epoch:  1 Batch:  2\n",
      "Epoch:  1 Batch:  3\n",
      "Epoch:  1 Batch:  4\n",
      "Epoch:  1 Batch:  5\n",
      "Epoch:  1 Batch:  6\n",
      "Epoch:  1 Batch:  7\n",
      "Epoch:  1 Batch:  8\n",
      "Epoch:  1 Batch:  9\n",
      "Epoch:  1 Batch:  10\n",
      "Epoch:  1 Batch:  11\n",
      "Epoch:  1 Batch:  12\n",
      "Epoch:  1 Batch:  13\n",
      "Epoch:  1 Batch:  14\n",
      "Epoch:  1 Batch:  15\n",
      "Epoch:  1 Batch:  16\n",
      "Epoch:  1 Batch:  17\n",
      "Epoch:  1 Batch:  18\n",
      "Epoch:  1 Batch:  19\n",
      "Epoch:  2 Batch:  0\n",
      "Epoch:  2 Batch:  1\n",
      "Epoch:  2 Batch:  2\n",
      "Epoch:  2 Batch:  3\n",
      "Epoch:  2 Batch:  4\n",
      "Epoch:  2 Batch:  5\n",
      "Epoch:  2 Batch:  6\n",
      "Epoch:  2 Batch:  7\n",
      "Epoch:  2 Batch:  8\n",
      "Epoch:  2 Batch:  9\n",
      "Epoch:  2 Batch:  10\n",
      "Epoch:  2 Batch:  11\n",
      "Epoch:  2 Batch:  12\n",
      "Epoch:  2 Batch:  13\n",
      "Epoch:  2 Batch:  14\n",
      "Epoch:  2 Batch:  15\n",
      "Epoch:  2 Batch:  16\n",
      "Epoch:  2 Batch:  17\n",
      "Epoch:  2 Batch:  18\n",
      "Epoch:  2 Batch:  19\n",
      "Epoch:  3 Batch:  0\n",
      "Epoch:  3 Batch:  1\n",
      "Epoch:  3 Batch:  2\n",
      "Epoch:  3 Batch:  3\n",
      "Epoch:  3 Batch:  4\n",
      "Epoch:  3 Batch:  5\n",
      "Epoch:  3 Batch:  6\n",
      "Epoch:  3 Batch:  7\n",
      "Epoch:  3 Batch:  8\n",
      "Epoch:  3 Batch:  9\n",
      "Epoch:  3 Batch:  10\n",
      "Epoch:  3 Batch:  11\n",
      "Epoch:  3 Batch:  12\n",
      "Epoch:  3 Batch:  13\n",
      "Epoch:  3 Batch:  14\n",
      "Epoch:  3 Batch:  15\n",
      "Epoch:  3 Batch:  16\n",
      "Epoch:  3 Batch:  17\n",
      "Epoch:  3 Batch:  18\n",
      "Epoch:  3 Batch:  19\n",
      "Epoch:  4 Batch:  0\n",
      "Epoch:  4 Batch:  1\n",
      "Epoch:  4 Batch:  2\n",
      "Epoch:  4 Batch:  3\n",
      "Epoch:  4 Batch:  4\n",
      "Epoch:  4 Batch:  5\n",
      "Epoch:  4 Batch:  6\n",
      "Epoch:  4 Batch:  7\n",
      "Epoch:  4 Batch:  8\n",
      "Epoch:  4 Batch:  9\n",
      "Epoch:  4 Batch:  10\n",
      "Epoch:  4 Batch:  11\n",
      "Epoch:  4 Batch:  12\n",
      "Epoch:  4 Batch:  13\n",
      "Epoch:  4 Batch:  14\n",
      "Epoch:  4 Batch:  15\n",
      "Epoch:  4 Batch:  16\n",
      "Epoch:  4 Batch:  17\n",
      "Epoch:  4 Batch:  18\n",
      "Epoch:  4 Batch:  19\n",
      "Epoch:  5 Batch:  0\n",
      "Epoch:  5 Batch:  1\n",
      "Epoch:  5 Batch:  2\n",
      "Epoch:  5 Batch:  3\n",
      "Epoch:  5 Batch:  4\n",
      "Epoch:  5 Batch:  5\n",
      "Epoch:  5 Batch:  6\n",
      "Epoch:  5 Batch:  7\n",
      "Epoch:  5 Batch:  8\n",
      "Epoch:  5 Batch:  9\n",
      "Epoch:  5 Batch:  10\n",
      "Epoch:  5 Batch:  11\n",
      "Epoch:  5 Batch:  12\n",
      "Epoch:  5 Batch:  13\n",
      "Epoch:  5 Batch:  14\n",
      "Epoch:  5 Batch:  15\n",
      "Epoch:  5 Batch:  16\n",
      "Epoch:  5 Batch:  17\n",
      "Epoch:  5 Batch:  18\n",
      "Epoch:  5 Batch:  19\n",
      "Epoch:  6 Batch:  0\n",
      "Epoch:  6 Batch:  1\n",
      "Epoch:  6 Batch:  2\n",
      "Epoch:  6 Batch:  3\n",
      "Epoch:  6 Batch:  4\n",
      "Epoch:  6 Batch:  5\n",
      "Epoch:  6 Batch:  6\n",
      "Epoch:  6 Batch:  7\n",
      "Epoch:  6 Batch:  8\n",
      "Epoch:  6 Batch:  9\n",
      "Epoch:  6 Batch:  10\n",
      "Epoch:  6 Batch:  11\n",
      "Epoch:  6 Batch:  12\n",
      "Epoch:  6 Batch:  13\n",
      "Epoch:  6 Batch:  14\n",
      "Epoch:  6 Batch:  15\n",
      "Epoch:  6 Batch:  16\n",
      "Epoch:  6 Batch:  17\n",
      "Epoch:  6 Batch:  18\n",
      "Epoch:  6 Batch:  19\n",
      "Epoch:  7 Batch:  0\n",
      "Epoch:  7 Batch:  1\n",
      "Epoch:  7 Batch:  2\n",
      "Epoch:  7 Batch:  3\n",
      "Epoch:  7 Batch:  4\n",
      "Epoch:  7 Batch:  5\n",
      "Epoch:  7 Batch:  6\n",
      "Epoch:  7 Batch:  7\n",
      "Epoch:  7 Batch:  8\n",
      "Epoch:  7 Batch:  9\n",
      "Epoch:  7 Batch:  10\n",
      "Epoch:  7 Batch:  11\n",
      "Epoch:  7 Batch:  12\n",
      "Epoch:  7 Batch:  13\n",
      "Epoch:  7 Batch:  14\n",
      "Epoch:  7 Batch:  15\n",
      "Epoch:  7 Batch:  16\n",
      "Epoch:  7 Batch:  17\n",
      "Epoch:  7 Batch:  18\n",
      "Epoch:  7 Batch:  19\n",
      "Epoch:  8 Batch:  0\n",
      "Epoch:  8 Batch:  1\n",
      "Epoch:  8 Batch:  2\n",
      "Epoch:  8 Batch:  3\n",
      "Epoch:  8 Batch:  4\n",
      "Epoch:  8 Batch:  5\n",
      "Epoch:  8 Batch:  6\n",
      "Epoch:  8 Batch:  7\n",
      "Epoch:  8 Batch:  8\n",
      "Epoch:  8 Batch:  9\n",
      "Epoch:  8 Batch:  10\n",
      "Epoch:  8 Batch:  11\n",
      "Epoch:  8 Batch:  12\n",
      "Epoch:  8 Batch:  13\n",
      "Epoch:  8 Batch:  14\n",
      "Epoch:  8 Batch:  15\n",
      "Epoch:  8 Batch:  16\n",
      "Epoch:  8 Batch:  17\n",
      "Epoch:  8 Batch:  18\n",
      "Epoch:  8 Batch:  19\n",
      "Epoch:  9 Batch:  0\n",
      "Epoch:  9 Batch:  1\n",
      "Epoch:  9 Batch:  2\n",
      "Epoch:  9 Batch:  3\n",
      "Epoch:  9 Batch:  4\n",
      "Epoch:  9 Batch:  5\n",
      "Epoch:  9 Batch:  6\n",
      "Epoch:  9 Batch:  7\n",
      "Epoch:  9 Batch:  8\n",
      "Epoch:  9 Batch:  9\n",
      "Epoch:  9 Batch:  10\n",
      "Epoch:  9 Batch:  11\n",
      "Epoch:  9 Batch:  12\n",
      "Epoch:  9 Batch:  13\n",
      "Epoch:  9 Batch:  14\n",
      "Epoch:  9 Batch:  15\n",
      "Epoch:  9 Batch:  16\n",
      "Epoch:  9 Batch:  17\n",
      "Epoch:  9 Batch:  18\n",
      "Epoch:  9 Batch:  19\n",
      "Training accuracy:   99.9%.\n",
      "Validation accuracy: 97.9%.\n",
      "Test accuracy: 98.2%.\n"
     ]
    }
   ],
   "source": [
    "# Trained the model on MNIST data\n",
    "trained_resnet = train_model(resnet, criterion, optimizer, trainloader_MNIST, val_loader_MNIST, num_epochs=10)\n",
    "test_model(trained_resnet, testloader_MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26496\\3486298027.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m all_svhm_train_data = torchvision.datasets.SVHN(root='./data', train=True,\n\u001b[1;32m----> 8\u001b[1;33m                                         download=True, transform=transform)\n\u001b[0m\u001b[0;32m      9\u001b[0m all_svhm_test_data = torchvision.datasets.SVHN(root='./data', train=True,\n\u001b[0;32m     10\u001b[0m                                         download=True, transform=transform)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'train'"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "all_svhm_train_data = torchvision.datasets.SVHN(root='./data', split= 'train'\n",
    "                                        download=True, transform=transform)\n",
    "all_svhm_test_data = torchvision.datasets.SVHN(root='./data', split= 'test'\n",
    "                                        download=True, transform=transform)\n",
    "svhm_test_set = torch.utils.data.Subset(all_svhm_train_data,list(range(10000)))\n",
    "svhm_val_set  = torch.utils.data.Subset(all_svhm_train_data,list(range(10000, 20000)))\n",
    "svhm_test_set  = torch.utils.data.Subset(all_svhm_train_data,list(range(10000)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# svhn_train_loader = torch.utils.data.DataLoader(all_svhm_data,\n",
    "#                                           batch_size=batch_size,\n",
    "#                                           shuffle=True,\n",
    "#                                           num_workers=2)\n",
    "\n",
    "\n",
    "# trainset_MNIST_big = torchvision.datasets.ImageNet(root='./data', train=True,\n",
    "#                                         download=True, transform=transform)\n",
    "\n",
    "# svhm_test_set = torch.utils.data.Subset(all_svhm_data,list(range(10000)))\n",
    "\n",
    "# trainloader_MNIST = torch.utils.data.DataLoader(trainset_MNIST, batch_size=batch_size,\n",
    "#                                           shuffle=True, num_workers=2)\n",
    "\n",
    "# val_set_MNIST = torch.utils.data.Subset(trainset_MNIST_big,list(range(10000, 20000)))\n",
    "# val_loader_MNIST = torch.utils.data.DataLoader(val_set_MNIST, batch_size=batch_size,\n",
    "#                                           shuffle=True, num_workers=2)\n",
    "                                          \n",
    "# testset_MNIST = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "#                                        download=True, transform=transform)\n",
    "# testloader_MNIST = torch.utils.data.DataLoader(testset_MNIST, batch_size=batch_size,\n",
    "#                                          shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chose ResNet-18 as CNN model\n",
    "resnet_svhn = torchvision.models.resnet18(pretrained= False)\n",
    "resnet.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "optimizer = torch.optim.Adam(resnet.parameters(), lr=0.001)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a5c66bde2355861cc8693a3cdfa3344b8bab0badfdde7d85b45cac752ce368b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
